# âœˆï¸ Flight Delay Prediction - MLOps Project

## ğŸ“‹ Table des matiÃ¨res
- [Vue d'ensemble](#vue-densemble)
- [Architecture du projet](#architecture-du-projet)
- [DonnÃ©es](#donnÃ©es)
- [Phase 1: DÃ©veloppement exploratoire](#phase-1-dÃ©veloppement-exploratoire)
- [Phase 2: Industrialisation locale](#phase-2-industrialisation-locale)
- [Phase 3: CI/CD et Orchestration](#phase-3-cicd-et-orchestration)
- [Installation et utilisation](#installation-et-utilisation)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)

---

## ğŸ¯ Vue d'ensemble

Ce projet a pour objectif de prÃ©dire les retards dâ€™arrivÃ©e des vols en combinant des modÃ¨les de Machine Learning et des pratiques MLOps modernes.
Il comprend une phase exploratoire sur Kaggle, suivie dâ€™une industrialisation complÃ¨te avec DVC, MLflow, Airflow, Docker et une API FastAPI pour lâ€™infÃ©rence.

**Objectif**: PrÃ©dire le retard d'arrivÃ©e (`ARR_DELAY`) d'un vol en fonction de caractÃ©ristiques comme la compagnie aÃ©rienne, l'aÃ©roport de dÃ©part/arrivÃ©e, l'heure prÃ©vue, la distance, etc.

---

## ğŸ—ï¸ Architecture du projet


<img width="1116" height="668" alt="image" src="https://github.com/user-attachments/assets/5b90ea89-db96-48ef-b02c-980b56ec7805" />





```
flight-delay-prediction/
â”œâ”€â”€ .dvc/                       # Configuration DVC
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml             # Pipeline CI (tests, validation)
â”‚       â””â”€â”€ cd.yaml            # Pipeline CD (build Docker, dÃ©ploiement)
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ dvc_pipeline_dag.py # DAG Airflow pour orchestration DVC
â”‚   â”œâ”€â”€ Dockerfile             # Image Airflow personnalisÃ©e
â”‚   â”œâ”€â”€ docker-compose.yml     # Configuration Airflow
â”‚   â””â”€â”€ requirements-docker.txt # DÃ©pendances Airflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # DonnÃ©es brutes (non versionnÃ©es)
â”‚   â””â”€â”€ processed/             # DonnÃ©es transformÃ©es (versionnÃ©es avec DVC)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ build_dataset.py   # Construction du dataset
â”‚   â”‚   â””â”€â”€ prepare_data.py    # Pipeline de prÃ©paration
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ datetime_features.py # Feature engineering temporel
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ encoding.py        # Encodage des variables catÃ©gorielles
â”‚   â”‚   â””â”€â”€ outliers.py        # Filtrage des outliers
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py           # EntraÃ®nement des modÃ¨les
â”‚   â”‚   â”œâ”€â”€ evaluate.py        # Ã‰valuation
â”‚   â”‚   â”œâ”€â”€ evaluate_evidently.py # Monitoring Evidently
â”‚   â”‚   â””â”€â”€ utils.py           # Fonctions utilitaires
â”‚   â””â”€â”€ predict.py             # Logique de prÃ©diction 
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                # API FastAPI
â”œâ”€â”€ models/                    # ModÃ¨les entraÃ®nÃ©s (versionnÃ©s avec DVC)
â”œâ”€â”€ evaluation/                # MÃ©triques et visualisations
â”œâ”€â”€ reports/                   # Rapports Evidently
â”œâ”€â”€ .gitignore                 # Fichiers Git Ã  ignorer
â”œâ”€â”€ .dvcignore                 # Fichiers DVC Ã  ignorer
â”œâ”€â”€ dvc.yaml                   # Pipeline DVC
â”œâ”€â”€ dvc.lock                   # Verrouillage du pipeline DVC
â”œâ”€â”€ params.yaml                # HyperparamÃ¨tres
â”œâ”€â”€ Dockerfile                 # Conteneurisation API
â”œâ”€â”€ requirements.txt           # DÃ©pendances principales
â”œâ”€â”€ requirements_api.txt       # DÃ©pendances API
â””â”€â”€ requirements_ci.txt        # DÃ©pendances CI/CD
```

---

## ğŸ“Š DonnÃ©es

### Source
Dataset officiel disponible sur Kaggle:
- **Nom**: [Airline Delay and Cancellation Data (2009-2018)](https://www.kaggle.com/datasets/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018)
- **PÃ©riode**: 2009 - 2018
- **Taille originale**: Plusieurs millions de vols par annÃ©e

### StratÃ©gie d'Ã©chantillonnage

Vu la taille importante des donnÃ©es (plusieurs Go), un Ã©chantillonnage stratifiÃ© a Ã©tÃ© appliquÃ©:

- **100,000 lignes par annÃ©e** (rÃ©parties uniformÃ©ment sur les 12 mois)
- **~8,333 lignes par mois** pour assurer une distribution temporelle Ã©quilibrÃ©e
- Ã‰chantillonnage alÃ©atoire avec `random_state=42` pour la reproductibilitÃ©

#### Variables sÃ©lectionnÃ©es

| Variable | Description |
|----------|-------------|
| `FL_DATE` | Date du vol |
| `OP_CARRIER` | Code de la compagnie aÃ©rienne |
| `OP_CARRIER_FL_NUM` | NumÃ©ro du vol |
| `ORIGIN` | AÃ©roport de dÃ©part |
| `DEST` | AÃ©roport de destination |
| `CRS_DEP_TIME` | Heure prÃ©vue de dÃ©part |
| `CRS_ARR_TIME` | Heure prÃ©vue d'arrivÃ©e |
| `CRS_ELAPSED_TIME` | Temps prÃ©vu de vol |
| `DISTANCE` | Distance du vol |
| `DEP_DELAY` | Retard au dÃ©part |
| `TAXI_OUT` | Temps entre gate et dÃ©collage |
| `WHEELS_OFF` | Heure rÃ©elle du dÃ©collage |
| `WHEELS_ON` | Heure rÃ©elle d'atterrissage |
| `TAXI_IN` | Temps entre atterrissage et gate |
| `CANCELLED` | Vol annulÃ© (0/1) |
| `DIVERTED` | Vol dÃ©tournÃ© (0/1) |
| **`ARR_DELAY`** | **Retard d'arrivÃ©e (cible)** |

### RÃ©sultat final
- **Shape**: (983,294, 19)
- **PÃ©riode**: 2009-2018
- **Distribution**: Ã‰quilibrÃ©e par annÃ©e et par mois

---

## ğŸ”¬ Phase 1: DÃ©veloppement exploratoire

**Environnement**: Kaggle Notebooks

Cette phase initiale a permis de valider la faisabilitÃ© du projet dans un environnement flexible.

### TÃ¢ches rÃ©alisÃ©es

| TÃ¢che | Description |
|-------|-------------|
| **EDA** | Exploration des donnÃ©es, analyse des distributions, corrÃ©lations |
| **Fusion & nettoyage** | Ã‰chantillonnage des 10 annÃ©es, gestion des valeurs manquantes |
| **Feature engineering** | Extraction de features temporelles (heure, jour, mois) et historiques (moyennes par compagnie/aÃ©roport, etc) |
| **EntraÃ®nement** | Test de plusieurs algorithmes (XGBoost, LightGBM, CatBoost, Random Forest) |
| **Documentation** | Notebook propre et reproductible |


### Insights clÃ©s
- Les retards au dÃ©part (`DEP_DELAY`) sont fortement corrÃ©lÃ©s avec les retards Ã  l'arrivÃ©e
- Les aÃ©roports et compagnies ont des patterns de retard distincts
- Les heures de pointe (matin et soir) prÃ©sentent plus de retards
- Les vols longue distance sont plus susceptibles de rÃ©cupÃ©rer du retard

### Livrable
âœ… Notebook Kaggle finalisÃ© avec modÃ¨le entraÃ®nÃ© et features calculÃ©es

---

## ğŸš€ Phase 2: Industrialisation locale

**Environnement**: GitHub + Machine locale + Docker

Cette phase a transformÃ© le code exploratoire en un projet MLOps production-ready.

### TÃ¢ches rÃ©alisÃ©es

| TÃ¢che | Description |
|-------|-------------|
| **Structuration** | Organisation du code en modules (`/src`, `/data`, `/models`) |
| **DVC** | Versioning des donnÃ©es et crÃ©ation du pipeline `dvc.yaml` |
| **MLflow** | Tracking des expÃ©riences et enregistrement des modÃ¨les |
| **API FastAPI** | DÃ©veloppement de l'API d'infÃ©rence |
| **Docker** | Conteneurisation complÃ¨te de l'API  |

### ğŸ“¦ Pipeline DVC

Le pipeline est dÃ©fini dans `dvc.yaml` et comprend 4 Ã©tapes:

```yaml
stages:
  1. prepare_data    # PrÃ©paration et split des donnÃ©es
  2. train_model     # EntraÃ®nement avec CV et MLflow
  3. evaluate        # Ã‰valuation sur le test set
  4. evaluate_evidently # GÃ©nÃ©ration de rapports de monitoring
```

**ExÃ©cution**:
```bash
dvc repro
```

### ğŸ“Š MLflow Tracking

Tous les modÃ¨les sont trackÃ©s avec MLflow:
- HyperparamÃ¨tres
- MÃ©triques de cross-validation (MAE, RMSE, RÂ²)
- MÃ©triques par fold
- ModÃ¨les enregistrÃ©s

**Interface MLflow**:
```bash
mlflow ui
```
<img width="1892" height="818" alt="Capture d&#39;Ã©cran 2026-01-02 124926" src="https://github.com/user-attachments/assets/4ae14ce2-94a7-4b7c-a555-0b2d975ef7dc" />

### ğŸ“„ Visualisation avec Evidently

AprÃ¨s avoir suivi le pipeline et trackÃ© les modÃ¨les avec MLflow, un **rapport Evidently** est gÃ©nÃ©rÃ© pour le modÃ¨le `best_model` afin dâ€™analyser ses performances et la qualitÃ© des prÃ©dictions.

**GÃ©nÃ©ration et ouverture du rapport** :  

```bash
# Lance la visualisation du rapport dans le navigateur
start reports/evidently_regression_report.html
```

## Contenu du dossier `reports/` aprÃ¨s gÃ©nÃ©ration
```
reports/
â”œâ”€â”€ evidently_regression_report.html  # Rapport interactif
â””â”€â”€ evidently_regression_report.json  # DonnÃ©es brutes utilisÃ©es par Evidently
```
<img width="1876" height="943" alt="Capture d&#39;Ã©cran 2026-01-02 122020" src="https://github.com/user-attachments/assets/1a195f0f-6c64-4af2-b4cb-14575cb1a43d" />

### Ce rapport permet de visualiser :

- Distribution des prÃ©dictions vs valeurs rÃ©elles
- Analyse des features importantes
- Ã‰volution des erreurs par sous-groupes
- DÃ©tection de dÃ©rives (drifts) ou anomalies


### ğŸŒ API FastAPI

L'API expose deux endpoints:

#### `GET /`
VÃ©rification de l'Ã©tat de l'API

#### `POST /predict`
PrÃ©diction du retard d'arrivÃ©e

**Exemple de requÃªte**:
```json
{
  "flight_date": "2025-12-19",
  "airline": 19,
  "flight_number": 3202,
  "origin_airport": 305,
  "dest_airport": 56,
  "scheduled_dep_time": 1420.0,
  "dep_delay": 5.0,
  "taxi_out": 18.0,
  "wheels_off": 1432.0,
  "scheduled_arr_time": 1600.0,
  "scheduled_elapsed_time": 100.0,
  "distance": 450.0,
  "year": 2025,
  "month": 12
}
```

**RÃ©ponse**:
```json
{
  "predicted_arrival_delay": 1.9828128814697266
}
```

### ğŸ³ Docker

L'API est conteneurisÃ© pour un dÃ©ploiement simplifiÃ©:

```dockerfile
FROM python:3.11-slim
# Installation des dÃ©pendances
# Copie des modÃ¨les et donnÃ©es nÃ©cessaires
# Exposition du port 8000
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Livrable
âœ… Projet MLOps structurÃ©, pipeline versionnÃ©, modÃ¨le conteneurisÃ© avec API fonctionnelle

---

## âš™ï¸ Phase 3: CI/CD et Orchestration

**Environnement**: GitHub Actions + Airflow + Docker

Cette phase a ajoutÃ© l'automatisation complÃ¨te avec des pipelines CI/CD et l'orchestration du workflow MLOps.

### TÃ¢ches rÃ©alisÃ©es

| TÃ¢che | Description |
|-------|-------------|
| **GitHub Actions CI** | Tests automatisÃ©s, validation du code, test du pipeline de donnÃ©es |
| **GitHub Actions CD** | Build et dÃ©ploiement automatique des images Docker |
| **Airflow** | Orchestration du pipeline DVC avec DAG |
| **Docker Compose** | Configuration multi-conteneurs (Airflow + API) |

### ğŸ”„ Pipeline CI (Continuous Integration)

Le workflow CI (`ci.yml`) s'exÃ©cute automatiquement Ã  chaque push ou pull request sur la branche `main`.

**Jobs CI**:

1. **build-test**: VÃ©rification de base du code
   - Checkout du code
   - Installation de Python 3.13
   - Installation des dÃ©pendances
   - Compilation du code source
   - ExÃ©cution des tests unitaires

2. **test-data-pipeline**: Test du pipeline de donnÃ©es
   - TÃ©lÃ©chargement des donnÃ©es depuis Google Drive
   - ExÃ©cution de `prepare_data.py`
   - VÃ©rification de la crÃ©ation des fichiers traitÃ©s

3. **test-api**: Test de l'API FastAPI
   - TÃ©lÃ©chargement des modÃ¨les prÃ©-entraÃ®nÃ©s
   - DÃ©marrage de l'API avec Uvicorn
   - Test de la route `/` (health check)
   - Test de la route `/predict` avec une requÃªte rÃ©elle

**ExÃ©cution**:
```bash
# DÃ©clenchÃ© automatiquement sur push/PR
# Ou manuellement via GitHub Actions UI
```
<img width="1886" height="859" alt="Capture d&#39;Ã©cran 2026-01-01 022053" src="https://github.com/user-attachments/assets/bd882fb7-d750-48bb-af47-bb69949ad80b" />

### ğŸš€ Pipeline CD (Continuous Delivery)

Le workflow CD (`cd.yaml`) s'exÃ©cute automatiquement aprÃ¨s le succÃ¨s du pipeline CI.
Il permet de prÃ©parer les artefacts nÃ©cessaires au dÃ©ploiement, sans dÃ©ploiement automatique en production.

**Jobs CD** :

1. **build-docker** : Construction des images Docker
   - TÃ©lÃ©chargement des donnÃ©es depuis Google Drive
   - Build de l'image API (`flight-delay-api:latest`)
   - Build de l'image Airflow (`flight-delay-airflow:latest`)
   - Sauvegarde des images comme artifacts

2. **prepare-deploy** : PrÃ©paration au dÃ©ploiement
   - TÃ©lÃ©chargement des images Docker
   - Chargement des images
   - Images prÃªtes pour un dÃ©ploiement manuel ou futur automatisÃ©


### ğŸ¯ Orchestration avec Airflow

Airflow permet d'orchestrer le pipeline MLOps de maniÃ¨re programmÃ©e et automatisÃ©e.

**DAG principal** (`dvc_pipeline_dag.py`):
```python
# ExÃ©cute le pipeline DVC complet
run_dvc_repro = BashOperator(
    task_id="run_dvc_repro",
    bash_command="cd /opt/airflow/project && dvc repro"
)
```

**Configuration Airflow**:
- Image personnalisÃ©e avec toutes les dÃ©pendances ML
- Montage du projet via volumes Docker
- ExÃ©cution manuelle ou programmÃ©e du pipeline


### ğŸ“¦ Configuration Docker Multi-Conteneurs

**docker-compose.yml** configure l'environnement Airflow complet:
- Postgres (base de donnÃ©es Airflow)
- Redis (file d'attente des tÃ¢ches)
- Airflow Webserver (interface UI)
- Airflow Scheduler (orchestrateur)
- Airflow Worker (exÃ©cuteur de tÃ¢ches)

### ğŸ” Gestion des DonnÃ©es

Les donnÃ©es volumineuses sont hÃ©bergÃ©es sur Google Drive et tÃ©lÃ©chargÃ©es automatiquement dans les workflows CI/CD:
- DonnÃ©es brutes: `df_final.csv`
- DonnÃ©es traitÃ©es: `X_train.csv`, `y_train.csv`
- ModÃ¨les: `best_model.pkl`, `encoder.pkl`, `feature_names.pkl`

### Livrable
âœ… Pipelines CI/CD configurÃ©s, orchestration Airflow opÃ©rationnelle, dÃ©ploiement Docker prÃªt pour lâ€™automatisation

---

## ğŸ’» Installation et utilisation

### PrÃ©requis
- Python 3.11+
- Docker (optionnel)
- DVC
- Git

### Installation locale

```bash
# Cloner le repository
git clone <repo-url>
cd flight-delay-mlops

# Installer les dÃ©pendances
pip install -r requirements.txt

# ExÃ©cuter le pipeline(remote DVC configurÃ© en local)
dvc repro
```

### Lancement de l'API

**Avec Python**:
```bash
uvicorn api.main:app --reload
```

**Avec Docker**:
```bash
docker build -t flight-delay-api .
docker run -p 8000:8000 flight-delay-api
```

L'API sera accessible sur `http://localhost:8000`

<img width="1919" height="212" alt="Capture d&#39;Ã©cran 2026-01-02 130736" src="https://github.com/user-attachments/assets/249eb8db-1941-4452-b45c-035ee66d7885" />

### Test de l'API

Une fois l'API lancÃ©e, vous pouvez tester une prÃ©diction avec :
```bash
curl -X POST http://127.0.0.1:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "flight_date": "2025-12-19",
    "airline": 19,
    "flight_number": 3202,
    "origin_airport": 305,
    "dest_airport": 56,
    "scheduled_dep_time": 1420.0,
    "dep_delay": 5.0,
    "taxi_out": 18.0,
    "wheels_off": 1432.0,
    "scheduled_arr_time": 1600.0,
    "scheduled_elapsed_time": 100.0,
    "distance": 450.0,
    "year": 2025,
    "month": 12
  }'
```

Documentation interactive: `http://localhost:8000/docs`
<img width="1808" height="521" alt="Capture d&#39;Ã©cran 2026-01-02 131046" src="https://github.com/user-attachments/assets/011b9532-f741-4c5e-9afe-4c84a19b40ba" />


### Lancement d'Airflow

```bash
cd airflow

# Initialisation dâ€™Airflow (DB, user admin, permissions)
docker compose up -d --build airflow-init

# DÃ©marrage des services Airflow
docker compose up -d

```

**Identifiants par dÃ©faut**:
- Username: `airflow`
- Password: `airflow`

Pour exÃ©cuter le DAG DVC:
1. AccÃ©der Ã  l'interface Airflow
2. Activer le DAG `flight_delay_dvc_pipeline`
3. DÃ©clencher manuellement le DAG ou programmer son exÃ©cution selon un schedule appropriÃ©

Interface Airflow accessible sur `http://localhost:8080`

<img width="1917" height="953" alt="Capture d&#39;Ã©cran 2026-01-02 130617" src="https://github.com/user-attachments/assets/af258fac-a387-4b89-9e3c-efbcd2e1289d" />

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Data Science & ML
- **pandas** - Manipulation de donnÃ©es
- **scikit-learn** - Preprocessing et mÃ©triques
- **XGBoost, LightGBM, CatBoost** - Algorithmes de boosting
- **Random Forest** - Ensemble learning

### MLOps
- **DVC** - Versioning des donnÃ©es et des modÃ¨les
- **MLflow** - Tracking des expÃ©riences
- **Docker** - Conteneurisation
- **FastAPI** - API REST
- **Uvicorn** - Serveur ASGI
- **Evidently** - Monitoring de la qualitÃ© du modÃ¨le
- **Airflow** - Orchestration des workflows
- **GitHub Actions** - CI/CD automation

### Versioning & Collaboration
- **Git** - Versioning du code
- **GitHub** - HÃ©bergement du repository
- **GitHub Actions** - CI/CD pipelines

---


## ğŸ“ˆ RÃ©sultats

Les modÃ¨les ont Ã©tÃ© Ã©valuÃ©s sur lâ€™ensemble dâ€™entraÃ®nement Ã  lâ€™aide dâ€™une cross-validation 5-fold :

| ModÃ¨le        | MAE (Mean) | RÂ² (Mean) | MAE (Std) |
|---------------|------------|-----------|-----------|
| XGBoost       | ~6.18      | ~0.893    | ~0.0085  |
| LightGBM      | ~6.35      | ~0.887    | ~0.0081  |
| CatBoost      | ~6.32      | ~0.883    | ~0.0056  |
| Random Forest | ~6.82      | ~0.874    | ~0.0103  |

Le modÃ¨le **XGBoost**, ayant obtenu les meilleures performances en cross-validation, a ensuite Ã©tÃ© Ã©valuÃ© sur lâ€™ensemble de test indÃ©pendant :
### ğŸ§ª RÃ©sultats sur le jeu de test (XGBoost)

- **MAE** : 6.31  
- **RMSE** : 79.15  
- **RÂ²** : 0.89  

---


## ğŸ”® Ã‰volutions futures

- DÃ©ploiement du projet sur le cloud (AWS, GCP ou Azure)
- Orchestration avec Kubernetes pour plus de scalabilitÃ©
- Monitoring en production avec Prometheus et Grafana
- DÃ©veloppement dâ€™une interface web pour les utilisateurs finaux
- Tests de charge et optimisation des performances du modÃ¨le et de lâ€™API
